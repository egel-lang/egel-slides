Let's see how we could exploit the model.

For one, a concrete machine can be implemented with reference counting.
And reference counting is appealing for a number of reasons;
primarily since it's a local operation; whereas
most other schemes invest a lot into hiding that they need to
scan the entire memory to collect.

Then this model rewrites, so there's less need for tail-call
optimization. If you term rewrites to another term in constant
space, then that's all there's to it.

Furthermore, this is a trivialized model where at any point
in time the program state forms a graph that can be serialized
or shipped. That's not new, other languages can do that too,
but it's made very easy.

A pleasant property of the model is that when terms go out
of scope, they are immediately collected, and that allows
for a scheme where finalizers clean up resources. You'll never
need to worry anymore whether a file handle is closed again!
